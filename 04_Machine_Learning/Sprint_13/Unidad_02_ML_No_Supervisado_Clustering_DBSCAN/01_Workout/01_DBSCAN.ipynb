{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering No Jerárquico (II): DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cB59xpLzbebN"
   },
   "source": [
    "\n",
    "### Configuración"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "njVAlWHJbebN"
   },
   "source": [
    "Para comenzar ejecuta la siguiente celda que está únicamente dedicada a hacer los imports y configuraciones necesarias para poder funcionar correctamente con este notebook de apoyo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T10:07:50.015867Z",
     "start_time": "2020-11-17T10:07:49.417839Z"
    },
    "id": "invK-zQnbebO"
   },
   "outputs": [],
   "source": [
    "# Common imports\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Ignore useless warnings (see SciPy issue #5998)\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(X):\n",
    "    plt.plot(X[:, 0], X[:, 1], 'k.', markersize=2)\n",
    "\n",
    "def plot_centroids(centroids, weights=None, circle_color='w', cross_color='b'):\n",
    "    if weights is not None:\n",
    "        centroids = centroids[weights > weights.max() / 10]\n",
    "    plt.scatter(centroids[:, 0], centroids[:, 1],\n",
    "                marker='o', s=30, linewidths=8,\n",
    "                color=circle_color, zorder=10, alpha=0.9)\n",
    "    plt.scatter(centroids[:, 0], centroids[:, 1],\n",
    "                marker='x', s=15, linewidths=20,\n",
    "                color=cross_color, zorder=11, alpha=1)\n",
    "\n",
    "def plot_decision_boundaries(clusterer, X, resolution=1000, show_centroids=True,\n",
    "                             show_xlabels=True, show_ylabels=True):\n",
    "    mins = X.min(axis=0) - 0.1\n",
    "    maxs = X.max(axis=0) + 0.1\n",
    "    xx, yy = np.meshgrid(np.linspace(mins[0], maxs[0], resolution),\n",
    "                         np.linspace(mins[1], maxs[1], resolution))\n",
    "    Z = clusterer.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    plt.contourf(Z, extent=(mins[0], maxs[0], mins[1], maxs[1]),\n",
    "                cmap=\"Pastel2\")\n",
    "    plt.contour(Z, extent=(mins[0], maxs[0], mins[1], maxs[1]),\n",
    "                linewidths=1, colors='k')\n",
    "    plot_data(X)\n",
    "    if show_centroids:\n",
    "        plot_centroids(clusterer.cluster_centers_)\n",
    "\n",
    "    if show_xlabels:\n",
    "        plt.xlabel(\"$x_1$\", fontsize=14)\n",
    "    else:\n",
    "        plt.tick_params(labelbottom=False)\n",
    "    if show_ylabels:\n",
    "        plt.ylabel(\"$x_2$\", fontsize=14, rotation=0)\n",
    "    else:\n",
    "        plt.tick_params(labelleft=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DBSCAN (Density-Based Spatial Clustering of Applications with Noise) es un algoritmo de clustering que se basa en la densidad de los datos para formar clusters. A diferencia de métodos como k-means, DBSCAN no requiere que se especifique el número de clusters de antemano. En su lugar, identifica las áreas de alta densidad que están separadas entre sí por áreas de baja densidad.\n",
    "\n",
    "La principal ventaja de DBSCAN es su capacidad para encontrar clusters de cualquier forma y tamaño, y su habilidad para identificar y separar outliers o ruido de los datos. Es especialmente útil cuando no se tiene una idea clara del número de clusters o cuando los clusters pueden tener formas irregulares."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funcionamiento de DBSCAN\n",
    "\n",
    "Este algoritmo define los grupos como regiones continuas de alta densidad. Así es como funciona:\n",
    "\n",
    "+ Para cada instancia, el algoritmo cuenta cuántas instancias se encuentran dentro de una pequeña distancia `eps` (epsilon) de ella. Esta región se llama $vecindario-\\epsilon$ (en inglés $\\epsilon-neighborhood$). `eps` es un hiperparámetro del modelo, es decir nosotros tenemos que elegir el valor adecuado en cada caso.\n",
    "\n",
    "+ Si una instancia tiene al menos `min_samples` en su vecindario (incluyéndose a sí misma), entonces se considera una instancia central, o \"core instance\". En otras palabras, las instancias cores son aquellas que se encuentran en regiones densas (con \"muchos puntos\" -> \"min_samples\"). Si `min_samples` es otro hiperparámetro del modelo y lo tenemos que escoger nosotros, de nuevo dependiendo del contexto en el que estemos trabajando.\n",
    "\n",
    "+ El algoritmo considera que todas las instancias en la vecindad de una instancia central pertenecen al mismo clúster. Ten en cuenta que que este vecindario puede incluir otros casos centrales (o core instances) y por tanto va \"fusionando\" los vecindarios de esas otras instancias cores en un único cluster. Si el vecindario de la instancia 4 (core) incluye la 23, la 101 y la 1000 y, por ejemplo, la 23 es core también con instancias 12,106 y 45 entonces todas forman un único cluster (4,23,101,1000,12,106,45) y así sucesivamente.\n",
    "\n",
    "+ Cualquier instancia que no sea una instancia central y no tenga una en su vecindario se considera una \"anomalía\" (y,si repasas los pasos anteriores, no se le puede asignar ningún clúster y se la etiquetará como -1, como veremos)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$*$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kDeRPVcwbeeo"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TzxQQ-LAbeep"
   },
   "outputs": [],
   "source": [
    "X, y = make_moons(n_samples=1000, noise=0.05, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O sea que partimos del siguiente dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x = X[:,0], y = X[:,1])\n",
    "plt.xlabel(\"$X_1$\")\n",
    "plt.ylabel(\"$X_2$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el que podríamos decir que hay dos clusters o agrupaciones (el \"churro\" superior y el \"churro\" inferior), veamos cómo se las gasta DBSCAN para identificarlas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iZS09yrHbeeq"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN # Siempre, por ahora, tirando de sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tv-LbD-xbeer",
    "outputId": "bfb17063-aea6-4317-d552-f56cd427b365"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Empieza con un punto aleatorio y segun va montando un cluster, busca en los puntos vecinos\n",
    "eps: (epsilon) distancia sobre la que busca vecinos\n",
    "min_samples: minimo numero de vecinos para considerarse cluster\n",
    "'''\n",
    "dbscan = DBSCAN(eps=0.05,\n",
    "                min_samples=5)\n",
    "dbscan.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$*$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aSFmshOygUtV",
    "outputId": "751d0323-890d-4e06-d269-63721d357aac"
   },
   "outputs": [],
   "source": [
    "# El algoritmo\n",
    "print(dbscan)\n",
    "\n",
    "# Todos los datos etiquetados\n",
    "print(len(dbscan.labels_))\n",
    "\n",
    "# Los 10 primeros labels\n",
    "print(dbscan.labels_[:10])\n",
    "\n",
    "# Cuantos clusters ha montado\n",
    "print(np.unique(dbscan.labels_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como ya adelantábamos existe una clase -1 que significa que las instancias etiquetadas con dicho valor se consideran anomalías."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Los índices las instancias core se almacenan en el atributo `core_sample_indices_`, y los valores de las features de dichas instancias cores están disponibles en el atributo `components_`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "quyrO2Sfbeet",
    "outputId": "a9065bff-776b-4b5c-9ab6-4647892f4cad"
   },
   "outputs": [],
   "source": [
    "# Cuantos core_sample_indices_\n",
    "print(len(dbscan.core_sample_indices_))\n",
    "\n",
    "# Los indices de los 10 primeros core_sample\n",
    "print(dbscan.core_sample_indices_[:10])\n",
    "\n",
    "# La posicion (coordenadas) de los 5 primeros core_sample\n",
    "print(dbscan.components_[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cQlYTUJIbeex",
    "outputId": "5bce0c5c-a563-4900-8be0-bc25a56e2340"
   },
   "outputs": [],
   "source": [
    "# Aumentemos epsilon para que tenga mayor rango y se formen menos clusters\n",
    "dbscan2 = DBSCAN(eps=0.2)\n",
    "dbscan2.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pero como todo esto queda muy etéreo, vamos a representarlo gráficamente que siempre ayuda a aterrizarlo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rm9W9U6vbeex"
   },
   "outputs": [],
   "source": [
    "def plot_dbscan(dbscan, X, size, show_xlabels=True, show_ylabels=True):\n",
    "    core_mask = np.zeros_like(dbscan.labels_, dtype=bool)\n",
    "    core_mask[dbscan.core_sample_indices_] = True\n",
    "    anomalies_mask = dbscan.labels_ == -1\n",
    "    non_core_mask = ~(core_mask | anomalies_mask)\n",
    "\n",
    "    cores = dbscan.components_\n",
    "    anomalies = X[anomalies_mask]\n",
    "    non_cores = X[non_core_mask]\n",
    "    \n",
    "    plt.scatter(cores[:, 0], cores[:, 1],\n",
    "                c=dbscan.labels_[core_mask], marker='o', s=size, cmap=\"Paired\")\n",
    "    plt.scatter(cores[:, 0], cores[:, 1], marker='*', s=20, c=dbscan.labels_[core_mask])\n",
    "    plt.scatter(anomalies[:, 0], anomalies[:, 1],\n",
    "                c=\"r\", marker=\"x\", s=100)\n",
    "    plt.scatter(non_cores[:, 0], non_cores[:, 1], c=dbscan.labels_[non_core_mask], marker=\".\")\n",
    "    if show_xlabels:\n",
    "        plt.xlabel(\"$x_1$\", fontsize=14)\n",
    "    else:\n",
    "        plt.tick_params(labelbottom=False)\n",
    "    if show_ylabels:\n",
    "        plt.ylabel(\"$x_2$\", fontsize=14, rotation=0)\n",
    "    else:\n",
    "        plt.tick_params(labelleft=False)\n",
    "    plt.title(\"eps={:.2f}, min_samples={}\".format(dbscan.eps, dbscan.min_samples), fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O6bSndLbbeey",
    "outputId": "de4396ed-c332-464a-98b2-d08427acce9e"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 3.2))\n",
    "\n",
    "plt.subplot(121)\n",
    "plot_dbscan(dbscan, X, size=100)\n",
    "\n",
    "plt.subplot(122)\n",
    "plot_dbscan(dbscan2, X, size=600, show_ylabels=False)\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Nuestro dbscan, el de epsilon pequeño, marcó instancias como anomalías, además de siete grupos diferentes, queríamos grupos muy densos (instnacias concentradas en \"espacio\"). En cambio, en cuanto permitimos un eps mayor es decir si ampliamos el vecindario de cada instancia, tenemos la agrupación a la derecha, que hace una detección perfecta. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \"Predicciones\" con  DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorprendentemente, la clase DBSCAN no tiene un método predict(), aunque tiene un método fit_predict(). En otras palabras, no puede asignar clúster a una nueva instancia (datos que no estuvieran en el train con el que se haya construido el DBSCAN). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$*$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La idea es que partimos de un dataset ya \"etiquetado\", al usar el DBSCAN, y lo que hay que hacer ahora es usarlo como dataset de train de cualquier clasificador supervisado ya conocido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Por ejemplo, podemos entrenar un KNN para clasificación. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AXsI7_nsbee1"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZDisMBj9bee2",
    "outputId": "d67ec8d1-8457-441f-d1e6-7ac6a6eb009c"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "No tiene .predict. Ya están los datos etiquetados y se le deja al usuario predecir con\n",
    "el algoritmo de clasificacion que prefiera. Por ejemplo, KNN.\n",
    "'''\n",
    "knn = KNeighborsClassifier(n_neighbors=50)\n",
    "knn.fit(dbscan2.components_, dbscan2.labels_[dbscan2.core_sample_indices_]) # Fijate que se entrena con las instancias core, no con todas las instancias (aunque podríamos hacerlo con todas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ten en cuenta que solo entrenamos al clasificador en las instancias core, pero también podríamos haber elegido entrenarlo en todas las instancias, o en todas menos en las anomalías: esta elección depende de la tarea final. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y ahora podemos`hacer predicciones/etiquetar nuevas instancias no icluidas en el dataset inicial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uUi2phITbee4",
    "outputId": "60519c98-f469-44a4-9ab7-f0b6f897c5bf"
   },
   "outputs": [],
   "source": [
    "X_new = np.array([[-0.5, 0], [0, 0.5], [1, -0.1], [2, 1]])\n",
    "knn.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7J-O7eRubee5",
    "outputId": "da8e7c86-e305-459d-e4d5-6fec792a504e"
   },
   "outputs": [],
   "source": [
    "knn.predict_proba(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a ver donde estarían esos nuevos puntos, las regiones de decisión de KNN que explicarán porque los ha categorizado como tal y si nos interesa cambiar la clasficiación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ad9ZoPnPbee6",
    "outputId": "d0f7a5d4-364b-428b-bb49-d6bdda6db1be"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 3))\n",
    "plot_decision_boundaries(knn, X, show_centroids=False)\n",
    "plt.scatter(X_new[:, 0], X_new[:, 1], c=\"b\", marker=\"+\", s=200, zorder=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viendo esta situación podríamos querer establecer algún tipo de criterio para que los puntos como [-0.5, 0] o [2,1] sean considerados anomalías. Quizás que la distancia a los vecinos sea menor que un valor concreto y para distancias superiores lo consideramos una anomalía: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7dIK-Xf4bee-",
    "outputId": "35f4f827-3073-4609-a048-d655e69e3799"
   },
   "outputs": [],
   "source": [
    "y_dist, y_pred_idx = knn.kneighbors(X_new, n_neighbors=1) # método que \n",
    "                                                        #devuelve la distancia y el índice de los vecinos \n",
    "                                                        #indicados por n_neighbors (devuelve los vecinos ordenados \n",
    "                                                        #por distancia), es decir con n_neighbors = 1 recupero \n",
    "                                                        # el vecino más cercano\n",
    "y_pred = dbscan2.labels_[dbscan2.core_sample_indices_][y_pred_idx]\n",
    "y_pred[y_dist > 0.2] = -1 # Básicamente lo que dice es que si la distancia al vecino más cercano es 0.2 (el epsilon del modelo DBSCAN), en \n",
    "                        # este caso, quiere decir que es una anomalíaç\n",
    "                        # Si, no se queda con la clase de ese vecino\n",
    "print(y_pred)   \n",
    "y_pred.ravel()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En resumen, DBSCAN es un algoritmo muy simple pero potente capaz de identificar cualquier número de grupos de cualquier forma. Es resistente a los valores atípicos, y solo tiene dos hiperparámetros (eps y min_samples). \n",
    "\n",
    "Sin embargo, si la densidad varía significativamente entre los grupos, puede ser imposible capturar todos los grupos correctamente. Y además tiene otros \"inconvenientes\" en tiempo de computación que creecen no linealmente con el número de instancias. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "-3ahKAttbebk",
    "SOFiv4Cabebt",
    "HadA7N8kbeb6",
    "OuYcdqilbeb_",
    "12CmqpoSbecD",
    "3txEmmvjbecJ",
    "qzT3ThMhbecM",
    "TH1JrvmFbecS",
    "x0MyJ_kobecb",
    "wBlOdHi4becg",
    "IR2Wq5l2beck",
    "H0g-zXeEbedE",
    "i4n6Wrcobed0",
    "dqhF_cyEbed9",
    "9mGLoiLibeeC",
    "9Wz-L_NEbeeV",
    "RxsZOvw4beeo",
    "yLEXFg2kbee_",
    "CP4uzAAKbee_",
    "skYHMYpsbefF",
    "z5XKoCBDbefe",
    "-PDmMrZKbefg",
    "MSNlMbIdbefu",
    "xtYtPbUybef6"
   ],
   "name": "Unsupervised_learning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
